# OpenAI config
quarkus.langchain4j.azure-openai.endpoint=defined in environment
quarkus.langchain4j.azure-openai.api-key=defined in environment

# Set temperature & topP for less creative responses
quarkus.langchain4j.azure-openai.chat-model.temperature=0.1
quarkus.langchain4j.azure-openai.chat-model.top-p=0.1

# Log requests and responses in dev mode
%dev.quarkus.langchain4j.azure-openai.chat-model.log-requests=true
%dev.quarkus.langchain4j.azure-openai.chat-model.log-responses=true
# Log responses in test mode
%test.quarkus.langchain4j.azure-openai.chat-model.log-responses=true

# quarkus.micrometer.export.json.enabled=true
# quarkus.micrometer.export.json.path=metrics/json
# quarkus.micrometer.export.prometheus.path=metrics/prometheus

# Check consistency with @RegisterAiService fault tolerance configuration
quarkus.langchain4j.azure-openai.max-retries=3
quarkus.langchain4j.azure-openai.timeout=2m

# Directory to store RAG documents
app.docs-for-rag.dir=docs-for-rag

# Model for local embedding
quarkus.langchain4j.embedding-model.provider=dev.langchain4j.model.embedding.AllMiniLmL6V2QuantizedEmbeddingModel

# Disable console input in dev mode to avoid blocking the app
quarkus.console.disable-input=true

# Logging
quarkus.log.category."io.jefrajames".level=DEBUG
quarkus.log.category."dev.langchain4j".level=DEBUG
quarkus.log.console.format=%s%e%n